{
   "accelerator": {
      "name": "v3-8",
      "numCores": 8,
      "replicas": 1,
      "size": 8,
      "type": "tpu",
      "variant": "",
      "version": 3
   },
   "command": [
      "bash",
      "-c",
      "set -x\nset -u\n\ncat > testsetup.sh << 'TEST_SCRIPT_EOF'\nset -x\nset -u\nset -e\n\n# .bash_logout sometimes causes a spurious bad exit code, remove it.\nrm .bash_logout\n\npip install --upgrade pip\ngit clone https://github.com/huggingface/transformers.git\ncd transformers && pip install .\npip install -r examples/flax/_tests_requirements.txt\npip install --upgrade huggingface-hub urllib3 zipp\n\npip install tensorflow\npip install jax[tpu] -f https://storage.googleapis.com/jax-releases/libtpu_releases.html\n\npip install -r examples/flax/text-classification/requirements.txt\npython3 -c 'import flax; print(\"flax version:\", flax.__version__)'\nnum_devices=`python3 -c \"import jax; print(jax.device_count())\"`\nif [ \"$num_devices\" = \"1\" ]; then\n  echo \"No TPU devices detected\"\n  exit 1\nfi\n\n\nexport GCS_BUCKET=$(MODEL_DIR)\nexport OUTPUT_DIR='./bert-glue'\npython3 examples/flax/text-classification/run_flax_glue.py --model_name_or_path bert-base-cased \\\n  --output_dir ${OUTPUT_DIR} \\\n  --logging_dir ${OUTPUT_DIR} \\\n  --per_device_train_batch_size 4 \\\n  --task_name mnli --max_seq_length 512 --eval_steps 1000 --num_train_epochs 1 --per_device_train_batch_size 4 --per_device_eval_batch_size 4\n\n# Upload files from worker 0, and ignore CommandException for the rest workers in TPU pod\ngsutil -m cp -r ${OUTPUT_DIR} $(MODEL_DIR) || exit 0\n\n\nTEST_SCRIPT_EOF\n\ngcloud alpha compute tpus tpu-vm ssh xl-ml-test@$(cat /scripts/tpu_name) \\\n--zone=$(cat /scripts/zone) \\\n--ssh-key-file=/scripts/id_rsa \\\n--strict-host-key-checking=no \\\n--internal-ip \\\n--worker=all \\\n--command \"$(cat testsetup.sh)\"\n\nexit_code=$?\nbash /scripts/cleanup.sh\nexit $exit_code\n"
   ],
   "configMaps": [
      "gcs-buckets"
   ],
   "cpu": 1,
   "entrypoint": null,
   "frameworkPrefix": "flax.latest",
   "image": "google/cloud-sdk",
   "imageTag": "latest",
   "labels": {
      "accelerator": "v3-8",
      "benchmarkId": "flax.latest-bert-glue.mnli-func-v3-8-1vm",
      "frameworkVersion": "flax.latest",
      "mode": "func",
      "model": "bert-glue.mnli"
   },
   "memory": "2Gi",
   "metricConfig": {
      "sources": [
         {
            "tensorboard": {
               "aggregate_assertions": [ ],
               "exclude_tags": [
                  "_hparams_/session_start_info"
               ],
               "include_tags": [
                  {
                     "strategies": [
                        "FINAL"
                     ],
                     "tag_pattern": "*"
                  }
               ],
               "merge_runs": true
            }
         }
      ]
   },
   "mode": "func",
   "outputBucket": "$(OUTPUT_BUCKET)",
   "runTest": "export GCS_BUCKET=$(MODEL_DIR)\nexport OUTPUT_DIR='./bert-glue'\npython3 examples/flax/text-classification/run_flax_glue.py --model_name_or_path bert-base-cased \\\n  --output_dir ${OUTPUT_DIR} \\\n  --logging_dir ${OUTPUT_DIR} \\\n  --per_device_train_batch_size 4 \\\n  --task_name mnli --max_seq_length 512 --eval_steps 1000 --num_train_epochs 1 --per_device_train_batch_size 4 --per_device_eval_batch_size 4\n\n# Upload files from worker 0, and ignore CommandException for the rest workers in TPU pod\ngsutil -m cp -r ${OUTPUT_DIR} $(MODEL_DIR) || exit 0\n",
   "schedule": "0 8 * * *",
   "setup": "pip install --upgrade pip\ngit clone https://github.com/huggingface/transformers.git\ncd transformers && pip install .\npip install -r examples/flax/_tests_requirements.txt\npip install --upgrade huggingface-hub urllib3 zipp\n\npip install tensorflow\npip install jax[tpu] -f https://storage.googleapis.com/jax-releases/libtpu_releases.html\n\npip install -r examples/flax/text-classification/requirements.txt\npython3 -c 'import flax; print(\"flax version:\", flax.__version__)'\nnum_devices=`python3 -c \"import jax; print(jax.device_count())\"`\nif [ \"$num_devices\" = \"1\" ]; then\n  echo \"No TPU devices detected\"\n  exit 1\nfi\n\n",
   "testName": "flax.latest-bert-glue.mnli-func-v3-8-1vm",
   "timeout": 4500,
   "tpuSettings": {
      "preemptible": true,
      "requireTpuAvailableLabel": true,
      "reserved": "false",
      "softwareVersion": "tpu-ubuntu2204-base",
      "tpuVmCreateSleepSeconds": 60,
      "tpuVmDockerArgs": "",
      "tpuVmStartupScript": "echo Running startup script"
   },
   "volumeMap": {
      "scripts": {
         "claim": {
            "emptyDir": {
               "medium": "Memory"
            }
         },
         "mountPath": "/scripts",
         "name": "scripts",
         "readOnly": false
      }
   }
}
